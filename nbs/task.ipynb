{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "> Tasks to interact with the Archivematica REST API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from archivematica_tools.api import ArchivematicaAPIClient\n",
    "from archivematica_tools.aws import AwsClient\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class Task:\n",
    "\n",
    "    def __init__(self, dashboard_url: str, dashboard_username: str, dashboard_api_key: str,\n",
    "                 storage_service_url: str, storage_service_username: str, storage_service_password: str,\n",
    "                 aws_access_key_id: str, aws_secret_access_key: str, aws_region: str):\n",
    "        \"\"\"\n",
    "        Constructor for the Task class. Initializes the Matica API client and the AWS S3 client.\n",
    "\n",
    "        Args:\n",
    "            dashboard_url (str): URL for the Matica dashboard.\n",
    "            dashboard_username (str): Username for the Matica dashboard.\n",
    "            dashboard_api_key (str): API key for the Matica dashboard.\n",
    "            storage_service_url (str): URL for the storage service.\n",
    "            storage_service_username (str): Username for the storage service.\n",
    "            storage_service_password (str): Password for the storage service.\n",
    "            aws_access_key_id (str): AWS access key ID.\n",
    "            aws_secret_access_key (str): AWS secret access key.\n",
    "            aws_region (str): AWS region.\n",
    "        \"\"\"\n",
    "        self.matica_client = ArchivematicaAPIClient(dashboard_url, dashboard_username, dashboard_api_key,\n",
    "                                             storage_service_url, storage_service_username, storage_service_password)\n",
    "        self.aws_client = AwsClient(aws_access_key_id, aws_secret_access_key, aws_region)\n",
    "\n",
    "    @staticmethod\n",
    "    def ensure_slash_suffix(s: str) -> str:\n",
    "        \"\"\"\n",
    "        Ensures the specified string ends with a slash, adding one if it does not.\n",
    "\n",
    "        Args:\n",
    "            s (str): The string to process.\n",
    "\n",
    "        Returns:\n",
    "            str: The string guaranteed to end with a slash.\n",
    "        \"\"\"\n",
    "        return s if s.endswith('/') else f'{s}/'\n",
    "\n",
    "    @staticmethod\n",
    "    def main(dashboard_url: str, dashboard_username: str, dashboard_api_key: str,\n",
    "             storage_service_url: str, storage_service_username: str, storage_service_password: str,\n",
    "             aws_access_key_id: str, aws_secret_access_key: str, task_id: str, transfer_type: str, \n",
    "             transfer_name: str, file_path: str, location_uuid: str, processing_config: str, \n",
    "             bucket_name: str, transfer_source_prefix: str, aws_region: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Executes the main process. Uploads a ZIP file to S3, then triggers processing in Matica.\n",
    "\n",
    "        Args:\n",
    "            The following arguments are similar to those in the __init__ method.\n",
    "            task_id (str): Task ID.\n",
    "            transfer_type (str): Transfer type.\n",
    "            transfer_name (str): Transfer name.\n",
    "            file_path (str): File path.\n",
    "            location_uuid (str): Location UUID.\n",
    "            processing_config (str): Processing configuration.\n",
    "            bucket_name (str): Bucket name.\n",
    "            transfer_source_prefix (str): Transfer source prefix.\n",
    "            aws_region (str): AWS region.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The URL of the processed file if successful, None otherwise.\n",
    "        \"\"\"\n",
    "        \n",
    "        task = Task(dashboard_url, \n",
    "        dashboard_username,\n",
    "        dashboard_api_key,\n",
    "        storage_service_url,\n",
    "        storage_service_username,\n",
    "        storage_service_password,\n",
    "        aws_access_key_id,\n",
    "        aws_secret_access_key,\n",
    "        aws_region\n",
    "        )\n",
    "\n",
    "        matica_client = task.matica_client\n",
    "\n",
    "        transfer_source_prefix = Task.ensure_slash_suffix(transfer_source_prefix)\n",
    "        s3_path = f\"{transfer_source_prefix}{task_id}\"\n",
    "\n",
    "        task.aws_client.upload_to_s3_zip(file_path, s3_path, bucket_name)\n",
    "\n",
    "        transfer_UUID = task.matica_client.v2beta_package(transfer_type, \"\", location_uuid, \"/\" + s3_path, transfer_name, processing_config)\n",
    "\n",
    "        sip_UUID = matica_client.check_transfer_status(transfer_UUID)\n",
    "        ingest_UUID = matica_client.ingest(sip_UUID)\n",
    "\n",
    "        url = f\"https://s3.{aws_region}.amazonaws.com/{bucket_name}/{task.matica_client.get_current_full_path(ingest_UUID)}\"\n",
    "\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/archivematica_tools/blob/main/archivematica_tools/task.py#L12){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Task\n",
       "\n",
       ">      Task (dashboard_url:str, dashboard_username:str, dashboard_api_key:str,\n",
       ">            storage_service_url:str, storage_service_username:str,\n",
       ">            storage_service_password:str, aws_access_key_id:str,\n",
       ">            aws_secret_access_key:str, aws_region:str)\n",
       "\n",
       "Constructor for the Task class. Initializes the Matica API client and the AWS S3 client.\n",
       "\n",
       "Args:\n",
       "    dashboard_url (str): URL for the Matica dashboard.\n",
       "    dashboard_username (str): Username for the Matica dashboard.\n",
       "    dashboard_api_key (str): API key for the Matica dashboard.\n",
       "    storage_service_url (str): URL for the storage service.\n",
       "    storage_service_username (str): Username for the storage service.\n",
       "    storage_service_password (str): Password for the storage service.\n",
       "    aws_access_key_id (str): AWS access key ID.\n",
       "    aws_secret_access_key (str): AWS secret access key.\n",
       "    aws_region (str): AWS region."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/archivematica_tools/blob/main/archivematica_tools/task.py#L12){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Task\n",
       "\n",
       ">      Task (dashboard_url:str, dashboard_username:str, dashboard_api_key:str,\n",
       ">            storage_service_url:str, storage_service_username:str,\n",
       ">            storage_service_password:str, aws_access_key_id:str,\n",
       ">            aws_secret_access_key:str, aws_region:str)\n",
       "\n",
       "Constructor for the Task class. Initializes the Matica API client and the AWS S3 client.\n",
       "\n",
       "Args:\n",
       "    dashboard_url (str): URL for the Matica dashboard.\n",
       "    dashboard_username (str): Username for the Matica dashboard.\n",
       "    dashboard_api_key (str): API key for the Matica dashboard.\n",
       "    storage_service_url (str): URL for the storage service.\n",
       "    storage_service_username (str): Username for the storage service.\n",
       "    storage_service_password (str): Password for the storage service.\n",
       "    aws_access_key_id (str): AWS access key ID.\n",
       "    aws_secret_access_key (str): AWS secret access key.\n",
       "    aws_region (str): AWS region."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/archivematica_tools/blob/main/archivematica_tools/task.py#L47){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Task.main\n",
       "\n",
       ">      Task.main (dashboard_url:str, dashboard_username:str,\n",
       ">                 dashboard_api_key:str, storage_service_url:str,\n",
       ">                 storage_service_username:str, storage_service_password:str,\n",
       ">                 aws_access_key_id:str, aws_secret_access_key:str, task_id:str,\n",
       ">                 transfer_type:str, transfer_name:str, file_path:str,\n",
       ">                 location_uuid:str, processing_config:str, bucket_name:str,\n",
       ">                 transfer_source_prefix:str, aws_region:str)\n",
       "\n",
       "Executes the main process. Uploads a ZIP file to S3, then triggers processing in Matica.\n",
       "\n",
       "Args:\n",
       "    The following arguments are similar to those in the __init__ method.\n",
       "    task_id (str): Task ID.\n",
       "    transfer_type (str): Transfer type.\n",
       "    transfer_name (str): Transfer name.\n",
       "    file_path (str): File path.\n",
       "    location_uuid (str): Location UUID.\n",
       "    processing_config (str): Processing configuration.\n",
       "    bucket_name (str): Bucket name.\n",
       "    transfer_source_prefix (str): Transfer source prefix.\n",
       "    aws_region (str): AWS region.\n",
       "\n",
       "Returns:\n",
       "    Optional[str]: The URL of the processed file if successful, None otherwise."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/nakamura196/archivematica_tools/blob/main/archivematica_tools/task.py#L47){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Task.main\n",
       "\n",
       ">      Task.main (dashboard_url:str, dashboard_username:str,\n",
       ">                 dashboard_api_key:str, storage_service_url:str,\n",
       ">                 storage_service_username:str, storage_service_password:str,\n",
       ">                 aws_access_key_id:str, aws_secret_access_key:str, task_id:str,\n",
       ">                 transfer_type:str, transfer_name:str, file_path:str,\n",
       ">                 location_uuid:str, processing_config:str, bucket_name:str,\n",
       ">                 transfer_source_prefix:str, aws_region:str)\n",
       "\n",
       "Executes the main process. Uploads a ZIP file to S3, then triggers processing in Matica.\n",
       "\n",
       "Args:\n",
       "    The following arguments are similar to those in the __init__ method.\n",
       "    task_id (str): Task ID.\n",
       "    transfer_type (str): Transfer type.\n",
       "    transfer_name (str): Transfer name.\n",
       "    file_path (str): File path.\n",
       "    location_uuid (str): Location UUID.\n",
       "    processing_config (str): Processing configuration.\n",
       "    bucket_name (str): Bucket name.\n",
       "    transfer_source_prefix (str): Transfer source prefix.\n",
       "    aws_region (str): AWS region.\n",
       "\n",
       "Returns:\n",
       "    Optional[str]: The URL of the processed file if successful, None otherwise."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Task.main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
